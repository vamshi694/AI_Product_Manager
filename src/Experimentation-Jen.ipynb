{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv('API_KEY')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(conversation_history, user_query, is_initial_query):\n",
    "    \"\"\"\n",
    "    Construct a prompt that emulates the expertise and responsibilities of a Google Assistant Product Manager,\n",
    "    focusing on specified categories and indicating the potential for broader assistance in the future.\n",
    "    \"\"\"\n",
    "    if is_initial_query:\n",
    "        prompt_intro = (\n",
    "            \"You are an AI acting as a Technical Product Manager for Google Assistant, \"\n",
    "            \"specializing in evaluating new feature requests, strategizing new product developments, \"\n",
    "            \"and conducting root cause analysis/hypothesis testing for products and metrics. \"\n",
    "            \"Currently, you're adept at handling inquiries related to these three main areas, \"\n",
    "            \"but you're also capable of adapting and expanding your expertise to cover a wider range of topics in the future.\\n\\n\"\n",
    "        )\n",
    "    else:\n",
    "        prompt_intro = (\n",
    "            \"As you understand, the intent of the conversations can be categorized into new feature requests, strategizing new product developments, \"\n",
    "            \"and conducting root cause analysis/hypothesis testing for products and metrics. Use this categorization to ask clarifying questions, \"\n",
    "            \"following the approach of any Technical Product Manager, until you have all the necessary information for the task. If the user's intent \"\n",
    "            \"doesn't fall under any of these categories, simply provide the requested information and ONLY FOR THIS CASE introduce your persona and your role.\\n\\n\"\n",
    "            \"[Please adhere strictly to a maximum of 3-4 questions for the clarifying questions, asking them one at a time to ensure clarity.]\"\n",
    "            \"\\n\\n\"\n",
    "        )\n",
    "\n",
    "    prompt = prompt_intro + conversation_history + f\"\\nBusiness Professional: {user_query}\\nProduct Manager AI:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_response(conversation_history, user_query, is_initial_query):\n",
    "    \"\"\"\n",
    "    Generate a response that offers strategic advice, further questions, or insights,\n",
    "    leveraging the expertise of a Google Assistant Product Manager.\n",
    "    \"\"\"\n",
    "    prompt = construct_prompt(conversation_history, user_query, is_initial_query)\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=genai.types.GenerationConfig(\n",
    "            temperature=0.7)\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Connecting you to your AI-modeled Google Assistant Product Manager...\")\n",
    "    introduction = (\n",
    "        \"Hello, I'm designed to perform as a Google Assistant Product Manager, equipped to assist with \"\n",
    "        \"new feature requests, product development strategies, and metrics analysis. These are my core areas \"\n",
    "        \"of expertise. However, I'm continuously learning and expanding my capabilities to include a broader \"\n",
    "        \"spectrum of topics in the future. How can I assist you today?\"\n",
    "    )\n",
    "    print(introduction)\n",
    "    \n",
    "    conversation_history = \"\"\n",
    "    is_initial_query = True\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"Business Professional: \").strip()\n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Thank you for our discussion today. I look forward to assisting you further in the future!\")\n",
    "            break\n",
    "\n",
    "        ai_response = get_conversation_response(conversation_history, user_query, is_initial_query)\n",
    "        \n",
    "        # Update conversation history\n",
    "        conversation_history += f\"\\nBusiness Professional: {user_query}\\nProduct Manager AI: {ai_response}\"\n",
    "        is_initial_query = False\n",
    "        \n",
    "        print(f\"\\nBusiness Professional: {user_query}\")\n",
    "        print(\"\\n\")\n",
    "        print(f\"\\nProduct Manager AI: {ai_response}\")\n",
    "        print(\"#\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
